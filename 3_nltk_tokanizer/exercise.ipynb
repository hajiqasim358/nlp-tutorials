{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49bca8b",
   "metadata": {},
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''\n",
    "\n",
    "##### TODO: Write code here\n",
    "##### Hint: token has an attribute that can be used to detect a url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea27bb",
   "metadata": {},
   "source": [
    "(2) Extract all money transaction from below sentence along with currency. Output should be,\n",
    "\n",
    "two $\n",
    "\n",
    "500 €"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31cf41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www.data.gov/', 'http://www.science', 'http://data.gov.uk/.', 'http://www3.norc.org/gss+website/', 'http://www.europeansocialsurvey.org/.']\n"
     ]
    }
   ],
   "source": [
    "## Solution \n",
    "\n",
    "import spacy\n",
    "nlp = spacy.blank(\"en\")\n",
    "#nlp = spacy.load(\"en_core_web_sm\")  # this gives error as the model is not downloaded\n",
    "\n",
    "doc = nlp(text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "''')\n",
    "\n",
    "# separate sentences into words or tokens\n",
    "\n",
    "urls = []\n",
    "for token in doc:\n",
    "    if token.like_url:\n",
    "        urls.append(token.text)\n",
    "print(urls)  # ['http://www.data.gov/', 'http://www.science.gov/.', 'http://www.data.gov.uk/.', 'http://www3.norc.org/gss+website/', 'http://www.europeansocialsurvey.org/.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9559318",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "\n",
    "# TODO: Write code here\n",
    "# Hint: Use token.i for the index of a token and token.is_currency for currency symbol detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "152e8777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "transaction = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "doc = nlp(transaction)\n",
    "for token in doc:\n",
    "    if token.like_num and doc[token.i+1].is_currency:\n",
    "        print(token.text, doc[token.i+1].text)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
