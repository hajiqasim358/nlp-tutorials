{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad1161c",
   "metadata": {},
   "source": [
    "### Working with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f146b3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spaCy model if not already installed\n",
    "import spacy\n",
    "nlp  = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "253481c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. loves pav bhaji of karachi.\n",
      "Dr.\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "karachi\n",
      ".\n",
      "Hulk\n",
      "loves\n",
      "chat\n",
      "of\n",
      "islamabad\n",
      ".\n",
      "Hulk loves chat of islamabad.\n",
      "Dr.\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "karachi\n",
      ".\n",
      "Hulk\n",
      "loves\n",
      "chat\n",
      "of\n",
      "islamabad\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "doc = nlp(\"Dr. loves pav bhaji of karachi. Hulk loves chat of islamabad.\")\n",
    "\n",
    "# the spacy is object oriented library\n",
    "# so we can access different properties of the document object\n",
    "# like sentences, tokens, entities, etc.\n",
    "# Print sentences in the document\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)\n",
    "\n",
    "# Print individual words in each sentence\n",
    "    for sentence in doc.sents:\n",
    "        for token in sentence:\n",
    "            print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "955fa013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk \n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e72e311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Tokenizer from NLTK:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Dr.', 'loves pav bhaji of karachi.', 'Hulk loves chat of islamabad.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the sentence tokenizer from nltk\n",
    "print(\"Sentence Tokenizer from NLTK:\")\n",
    "sent_tokenize(\"Dr. loves pav bhaji of karachi. Hulk loves chat of islamabad.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31b1c3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Tokenizer from NLTK:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Dr',\n",
       " '.',\n",
       " 'loves',\n",
       " 'pav',\n",
       " 'bhaji',\n",
       " 'of',\n",
       " 'karachi',\n",
       " '.',\n",
       " 'Hulk',\n",
       " 'loves',\n",
       " 'chat',\n",
       " 'of',\n",
       " 'islamabad',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the word tokenizer from nltk\n",
    "print(\"\\nWord Tokenizer from NLTK:\")\n",
    "word_tokenize(\"Dr. loves pav bhaji of karachi. Hulk loves chat of islamabad.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e46a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the punkt package for nltk if not already downloaded\n",
    "# I have already installed it so commenting it out\n",
    "# nltk.download('punkt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
