{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1ad39b",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e50d447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d34470",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ab1cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfd9a5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "ate  |  ate\n",
      "adjustable  |  adjust\n",
      "rafting  |  raft\n",
      "ability  |  abil\n",
      "meeting  |  meet\n",
      "enjoying  |  enjoy\n",
      "fencing  |  fenc\n"
     ]
    }
   ],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\", \"enjoying\", \"fencing\"]\n",
    "for word in words:\n",
    "    print(word, \" | \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50298633",
   "metadata": {},
   "source": [
    "#### Stemming with Lemmatization to make correct base words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b701019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "ate  |  eat\n",
      "adjustable  |  adjustable\n",
      "rafting  |  raft\n",
      "ability  |  ability\n",
      "meeting  |  meeting\n",
      "enjoying  |  enjoy\n",
      "fencing  |  fence\n"
     ]
    }
   ],
   "source": [
    "# load a pre-trained English pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting enjoying fencing\")\n",
    "for token in doc:\n",
    "    print(token.text, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba8bd45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He  |  he\n",
      "was  |  be\n",
      "working  |  work\n",
      "until  |  until\n",
      "late  |  late\n",
      "night  |  night\n",
      ",  |  ,\n",
      "then  |  then\n",
      "he  |  he\n",
      "reached  |  reach\n",
      "home  |  home\n",
      "at  |  at\n",
      "morning  |  morning\n",
      "when  |  when\n",
      "the  |  the\n",
      "work  |  work\n",
      "was  |  be\n",
      "finished  |  finish\n",
      ",  |  ,\n",
      "all  |  all\n",
      "of  |  of\n",
      "the  |  the\n",
      "workers  |  worker\n",
      "wrre  |  wrre\n",
      "tired  |  tired\n",
      "but  |  but\n",
      "they  |  they\n",
      "wanted  |  want\n",
      "to  |  to\n",
      "complete  |  complete\n",
      "their  |  their\n",
      "duty  |  duty\n",
      "before  |  before\n",
      "they  |  they\n",
      "leave  |  leave\n",
      ".  |  .\n",
      "The  |  the\n",
      "manager  |  manager\n",
      "then  |  then\n",
      "paid  |  pay\n",
      "them  |  they\n",
      "with  |  with\n",
      "a  |  a\n",
      "more  |  more\n",
      "wage  |  wage\n",
      "they  |  they\n",
      "expected  |  expect\n",
      "to  |  to\n",
      "receive  |  receive\n",
      ".  |  .\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"He was working until late night, then he reached home at morning when the work was finished, all of the workers wrre tired but they wanted to complete their duty before they leave. The manager then paid them with a more wage they expected to receive.\")\n",
    "for token in doc:\n",
    "    print(token.text, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69a8c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite  |  despite\n",
      "the  |  the\n",
      "researchers  |  researcher\n",
      "’  |  '\n",
      "ongoing  |  ongoing\n",
      "investigations  |  investigation\n",
      "into  |  into\n",
      "adjustable  |  adjustable\n",
      "methodologies  |  methodology\n",
      "and  |  and\n",
      "evolving  |  evolve\n",
      "frameworks  |  framework\n",
      ",  |  ,\n",
      "the  |  the\n",
      "committee  |  committee\n",
      "reconvened  |  reconvene\n",
      "to  |  to\n",
      "reassess  |  reassess\n",
      "previously  |  previously\n",
      "established  |  establish\n",
      "findings  |  finding\n",
      ",  |  ,\n",
      "debating  |  debate\n",
      "the  |  the\n",
      "applicability  |  applicability\n",
      "of  |  of\n",
      "theoretical  |  theoretical\n",
      "constructs  |  construct\n",
      "and  |  and\n",
      "the  |  the\n",
      "feasibility  |  feasibility\n",
      "of  |  of\n",
      "implementing  |  implement\n",
      "scalable  |  scalable\n",
      "solutions  |  solution\n",
      ".  |  .\n",
      "Participants  |  participant\n",
      "were  |  be\n",
      "analyzing  |  analyze\n",
      ",  |  ,\n",
      "negotiating  |  negotiate\n",
      ",  |  ,\n",
      "and  |  and\n",
      "documenting  |  document\n",
      "their  |  their\n",
      "observations  |  observation\n",
      "while  |  while\n",
      "simultaneously  |  simultaneously\n",
      "coordinating  |  coordinate\n",
      "interdisciplinary  |  interdisciplinary\n",
      "meetings  |  meeting\n",
      ",  |  ,\n",
      "forecasting  |  forecast\n",
      "potential  |  potential\n",
      "disruptions  |  disruption\n",
      ",  |  ,\n",
      "and  |  and\n",
      "evaluating  |  evaluate\n",
      "the  |  the\n",
      "sustainability  |  sustainability\n",
      "of  |  of\n",
      "proposed  |  propose\n",
      "interventions  |  intervention\n",
      ".  |  .\n",
      "Activities  |  activity\n",
      "such  |  such\n",
      "as  |  as\n",
      "brainstorming  |  brainstorming\n",
      ",  |  ,\n",
      "prototyping  |  prototyping\n",
      ",  |  ,\n",
      "and  |  and\n",
      "reengineering  |  reengineering\n",
      "were  |  be\n",
      "enthusiastically  |  enthusiastically\n",
      "embraced  |  embrace\n",
      ",  |  ,\n",
      "although  |  although\n",
      "some  |  some\n",
      "members  |  member\n",
      "expressed  |  express\n",
      "reservations  |  reservation\n",
      "about  |  about\n",
      "the  |  the\n",
      "practicality  |  practicality\n",
      "of  |  of\n",
      "integrating  |  integrate\n",
      "emerging  |  emerge\n",
      "technologies  |  technology\n",
      "into  |  into\n",
      "legacy  |  legacy\n",
      "systems  |  system\n",
      ".  |  .\n"
     ]
    }
   ],
   "source": [
    "# load a pre-trained English pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Despite the researchers’ ongoing investigations into adjustable methodologies and evolving frameworks, the committee reconvened to reassess previously established findings, debating the applicability of theoretical constructs and the feasibility of implementing scalable solutions. Participants were analyzing, negotiating, and documenting their observations while simultaneously coordinating interdisciplinary meetings, forecasting potential disruptions, and evaluating the sustainability of proposed interventions. Activities such as brainstorming, prototyping, and reengineering were enthusiastically embraced, although some members expressed reservations about the practicality of integrating emerging technologies into legacy systems.\")\n",
    "for token in doc:\n",
    "    print(token.text, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3f0118",
   "metadata": {},
   "source": [
    "### custom Attribute ruler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3af4d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "937cca44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo  |  Yo\n",
      "bro  |  brother\n",
      ",  |  ,\n",
      "I  |  I\n",
      "was  |  be\n",
      "gon  |  go\n",
      "na  |  to\n",
      "hit  |  hit\n",
      "up  |  up\n",
      "that  |  that\n",
      "new  |  new\n",
      "joint  |   place\n",
      "downtown  |  downtown\n",
      "with  |  with\n",
      "Bra  |  brother\n",
      ",  |  ,\n",
      "but  |  but\n",
      "he  |  he\n",
      "said  |  say\n",
      "he  |  he\n",
      "’s  |  ’\n",
      "outta  |  out of\n",
      "town  |  town\n",
      "for  |  for\n",
      "the  |  the\n",
      "weekend  |  weekend\n",
      ".  |  .\n",
      "I  |  I\n",
      "was  |  be\n",
      "like  |  like\n",
      ",  |  ,\n",
      "“  |  \"\n",
      "Cuz  |  cuz\n",
      ",  |  ,\n",
      "you  |  you\n",
      "got  |  get\n",
      "ta  |  to\n",
      "be  |  be\n",
      "kidding  |  kid\n",
      "me  |  I\n",
      "!  |  !\n",
      "”  |  \"\n",
      "I  |  I\n",
      "really  |  really\n",
      "wanna  |  want to\n",
      "chill  |   relax\n",
      ",  |  ,\n",
      "grab  |  grab\n",
      "some  |  some\n",
      "brews  |   beers\n",
      ",  |  ,\n",
      "and  |  and\n",
      "wreck  |   defeat\n",
      "some  |  some\n",
      "noobs  |  noob\n",
      "on  |  on\n",
      "the  |  the\n",
      "PS5  |  PS5\n",
      ".  |  .\n",
      "Lemme  |  Lemme\n",
      "know  |  know\n",
      "if  |  if\n",
      "you  |  you\n",
      "'re  |  be\n",
      "down  |  down\n",
      "—  |  —\n",
      "it  |  it\n",
      "'s  |  be\n",
      "been  |  be\n",
      "a  |  a\n",
      "minute  |  minute\n",
      "since  |  since\n",
      "we  |  we\n",
      "had  |  have\n",
      "a  |  a\n",
      "proper  |  proper\n",
      "bro  |  brother\n",
      "night  |  night\n",
      ".  |  .\n",
      "The  |  the\n",
      "place  |  place\n",
      "has  |  have\n",
      "sick  |   great\n",
      "deals  |  deal\n",
      "on  |  on\n",
      "wings  |  wing\n",
      ",  |  ,\n",
      "and  |  and\n",
      "the  |  the\n",
      "vibe  |  vibe\n",
      "is  |  be\n",
      "kinda  |  kind of\n",
      "unreal  |  unreal\n",
      ".  |  .\n",
      "I  |  I\n",
      "heard  |  hear\n",
      "they  |  they\n",
      "even  |  even\n",
      "added  |  add\n",
      "a  |  a\n",
      "rooftop  |  rooftop\n",
      "lounge  |  lounge\n",
      ",  |  ,\n",
      "which  |  which\n",
      "sounds  |  sound\n",
      "great  |  great\n",
      "for  |  for\n",
      "kicking  |  kick\n",
      "back  |  back\n",
      ".  |  .\n",
      "After  |  after\n",
      "that  |  that\n",
      ",  |  ,\n",
      "we  |  we\n",
      "can  |  can\n",
      "bounce  |   go\n",
      "to  |  to\n",
      "my  |  my\n",
      "place  |  place\n",
      ",  |  ,\n",
      "maybe  |  maybe\n",
      "watch  |  watch\n",
      "a  |  a\n",
      "movie  |  movie\n",
      "or  |  or\n",
      "just  |  just\n",
      "relax  |  relax\n",
      "and  |  and\n",
      "talk  |  talk\n",
      ".  |  .\n",
      "Honestly  |  honestly\n",
      ",  |  ,\n",
      "I  |  I\n",
      "’m  |  ’m\n",
      "exhausted  |  exhausted\n",
      "from  |  from\n",
      "work  |  work\n",
      "and  |  and\n",
      "need  |  need\n",
      "to  |  to\n",
      "unwind  |  unwind\n",
      ".  |  .\n",
      "You  |  you\n",
      "in  |  in\n",
      "or  |  or\n",
      "what  |  what\n",
      "?  |  ?\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "\n",
    "#ar.add([[{\"TEXT\": \"bro\"}], {\"LEMMA\": \"brother\"}])\n",
    "ar.add(patterns=[[{\"TEXT\": \"bro\"}], [{\"TEXT\": \"Bra\"}]],attrs={\"LEMMA\": \"brother\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"wanna\"}]],attrs={\"LEMMA\": \"want to\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"gonna\"}]],attrs={\"LEMMA\": \" going to\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"gotta\"}]],attrs={\"LEMMA\": \"got to\"})        \n",
    "ar.add(patterns=[[{\"TEXT\": \"lemme\"}]],attrs={\"LEMMA\": \"let me\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"kinda\"}]],attrs={\"LEMMA\": \"kind of\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"outta\"}]],attrs={\"LEMMA\": \"out of\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"cuz\"}]],attrs={\"LEMMA\": \"   because\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"chill\"}]],attrs={\"LEMMA\": \" relax\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"brews\"}]],attrs={\"LEMMA\": \" beers\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"hit up\"}]],attrs={\"LEMMA\": \" visit\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"joint\"}]],attrs={\"LEMMA\": \" place\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"sick\"}]],attrs={\"LEMMA\": \" great\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"bounce\"}]],attrs={\"LEMMA\": \" go\"})\n",
    "ar.add(patterns=[[{\"TEXT\": \"wreck\"}]],attrs={\"LEMMA\": \" defeat\"})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "doc = nlp(\"Yo bro, I was gonna hit up that new joint downtown with Bra, but he said he’s outta town for the weekend. I was like, “Cuz, you gotta be kidding me!” I really wanna chill, grab some brews, and wreck some noobs on the PS5. Lemme know if you're down — it's been a minute since we had a proper bro night. The place has sick deals on wings, and the vibe is kinda unreal. I heard they even added a rooftop lounge, which sounds great for kicking back. After that, we can bounce to my place, maybe watch a movie or just relax and talk. Honestly, I’m exhausted from work and need to unwind. You in or what?\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, \" | \", token.lemma_)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51931ee3",
   "metadata": {},
   "source": [
    "# Worked on Stemming and Lemmatization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
